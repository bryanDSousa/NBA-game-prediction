{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glosario de términos\n",
    "\n",
    "MP -- Minutes Played\n",
    "\n",
    "FG -- Field Goals\n",
    "\n",
    "FGA -- Field Goal Attempts\n",
    "\n",
    "FG% -- Field Goal Percentage\n",
    "\n",
    "3P -- 3-Point Field Goals\n",
    "\n",
    "3PA -- 3-Point Field Goal Attempts\n",
    "\n",
    "3P% -- 3-Point Field Goal Percentage\n",
    "\n",
    "FT -- Free Throws\n",
    "\n",
    "FTA -- Free Throw Attempts\n",
    "\n",
    "FT% -- Free Throw Percentage\n",
    "\n",
    "ORB -- Offensive Rebounds\n",
    "\n",
    "DRB -- Defensive Rebounds\n",
    "\n",
    "TRB -- Total Rebounds\n",
    "\n",
    "AST -- Assists\n",
    "\n",
    "STL -- Steals\n",
    "\n",
    "BLK -- Blocks\n",
    "\n",
    "TOV -- Turnovers\n",
    "\n",
    "PF -- Personal Fouls\n",
    "\n",
    "PTS -- Points\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "OFF RATE: **offensive rating**  is a statistic used to measure either a teams offensive performance or an individual player's efficiency at producing points.\n",
    "\n",
    "**Defensive Player Rating** = (Players Points.Total FG%) + **Opponents Differential**= 1/5 of possessions - Times Fouled+ FTM* FT% * OAPOW( Official Adjusted Players Offensive Withstand). \n",
    "\n",
    "***********************************************************************************************\n",
    "\n",
    "DEFF RATE: **Defensive rating** is a statistic used to measure an individual player's efficiency at preventing the other team from scoring points\n",
    "\n",
    "**Defensive Player Rating** = (Players Steals.Blocks) + **Opponents Differential**= 1/5 of possessions - Times blown by + Deflections * OAPDW( Official Adjusted Players Defensive Withstand)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%matplotlib inline\n",
    "%pylab\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    boxcore_url       Date  Season          local_team  \\\n",
      "0  /boxscores/200910300PHI.html  2009Oct30  2010.0  Philadelphia 76ers   \n",
      "1  /boxscores/200911030PHI.html   2009Nov3  2010.0  Philadelphia 76ers   \n",
      "2  /boxscores/200911060PHI.html   2009Nov6  2010.0  Philadelphia 76ers   \n",
      "3  /boxscores/200911090PHI.html   2009Nov9  2010.0  Philadelphia 76ers   \n",
      "4  /boxscores/200911130PHI.html  2009Nov13  2010.0  Philadelphia 76ers   \n",
      "\n",
      "      visitor_team  local_pts  visitor_pts Result  local_Lose  local_Win  ...  \\\n",
      "0  Milwaukee Bucks         99           86      W         1.0        0.0  ...   \n",
      "1   Boston Celtics         74          105      L         1.0        2.0  ...   \n",
      "2  New Jersey Nets         97           94      W         2.0        2.0  ...   \n",
      "3     Phoenix Suns        115          119      L         3.0        3.0  ...   \n",
      "4        Utah Jazz         90          112      L         4.0        4.0  ...   \n",
      "\n",
      "   visitor_orb  visitor_orb_pct  visitor_pf  visitor_stl  visitor_stl_pct  \\\n",
      "0           12             23.5          27            7              7.1   \n",
      "1            7             23.3          21           10             11.3   \n",
      "2           12             27.9          24            6              6.8   \n",
      "3            6             17.1          18            4              4.3   \n",
      "4           13             35.1          15            9             10.2   \n",
      "\n",
      "   visitor_tov  visitor_tov_pct  visitor_trb_pct  visitor_trn  \\\n",
      "0           20             17.6             49.4           44   \n",
      "1           17             17.9             53.4           39   \n",
      "2           13             12.5             50.0           41   \n",
      "3           12             11.8             45.8           33   \n",
      "4           12             11.5             57.1           44   \n",
      "\n",
      "   visitor_true_shooting_pct  \n",
      "0                      0.461  \n",
      "1                      0.672  \n",
      "2                      0.514  \n",
      "3                      0.663  \n",
      "4                      0.605  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "partidos = pd.read_csv('partidos_join11_04_20_clean.csv')\n",
    "print(partidos.head(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxcore_url\n",
      "Date\n",
      "Season\n",
      "local_team\n",
      "visitor_team\n",
      "local_pts\n",
      "visitor_pts\n",
      "Result\n",
      "local_Lose\n",
      "local_Win\n",
      "local_Percentagewl\n",
      "local_3pa_rate\n",
      "local_Conf_position\n",
      "local_Home_lose\n",
      "local_Home_win\n",
      "local_ast\n",
      "local_ast_pct\n",
      "local_blk\n",
      "local_blk_pct\n",
      "local_def_rate\n",
      "local_drb\n",
      "local_drb_pct\n",
      "local_effective_fg_pct\n",
      "local_fg\n",
      "local_fg3\n",
      "local_fg3_pct\n",
      "local_fg3a\n",
      "local_fg_pct\n",
      "local_fga\n",
      "local_ft\n",
      "local_ft_pct\n",
      "local_fta\n",
      "local_fta_rate\n",
      "local_off_rate\n",
      "local_orb\n",
      "local_orb_pct\n",
      "local_pf\n",
      "local_stl\n",
      "local_stl_pct\n",
      "local_tov\n",
      "local_tov_pct\n",
      "local_trb_pct\n",
      "local_trn\n",
      "local_true_shooting_pct\n",
      "visitor_Lose\n",
      "visitor_Win\n",
      "visitor_Percentagewl\n",
      "visitor_3pa_rate\n",
      "visitor_Conf_position\n",
      "visitor_Away_lose\n",
      "visitor_Away_win\n",
      "visitor_ast\n",
      "visitor_ast_pct\n",
      "visitor_blk\n",
      "visitor_blk_pct\n",
      "visitor_def_rate\n",
      "visitor_drb\n",
      "visitor_drb_pct\n",
      "visitor_effective_fg_pct\n",
      "visitor_fg\n",
      "visitor_fg3\n",
      "visitor_fg3_pct\n",
      "visitor_fg3a\n",
      "visitor_fg_pct\n",
      "visitor_fga\n",
      "visitor_ft\n",
      "visitor_ft_pct\n",
      "visitor_fta\n",
      "visitor_fta_rate\n",
      "visitor_off_rate\n",
      "visitor_orb\n",
      "visitor_orb_pct\n",
      "visitor_pf\n",
      "visitor_stl\n",
      "visitor_stl_pct\n",
      "visitor_tov\n",
      "visitor_tov_pct\n",
      "visitor_trb_pct\n",
      "visitor_trn\n",
      "visitor_true_shooting_pct\n"
     ]
    }
   ],
   "source": [
    "for column in partidos.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo de variables compuestas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partidos['target'] = partidos['Local victory']\n",
    "\n",
    "partidos['LOCAL_Diferencia'] = partidos['localPoints'] - partidos['visitorPoints']\n",
    "partidos['VISITANTE_Diferencia'] = partidos['visitorPoints'] - partidos['localPoints']\n",
    "\n",
    "partidos['VISITANTE_porcentaje_victoria_Ultimos10'] = (partidos['VISITANTE_Ultimos10Victorias']) / (partidos['VISITANTE_Ultimos10Victorias'] + partidos['VISITANTE_Ultimos10Derrotas'])\n",
    "\n",
    "partidos['LOCAL_porcentaje_victoria_Ultimos10'] = (partidos['LOCAL_Ultimos10Victorias']) / (partidos['LOCAL_Ultimos10Victorias'] + partidos['LOCAL_Ultimos10Derrotas'])\n",
    "\n",
    "partidos['LOCAL_porcentaje_victoria_LOCAL'] = (partidos['LOCAL_Victorias_Local']) / (partidos['LOCAL_Victorias_Local'] + partidos['LOCAL_Derrotas_local'])\n",
    "\n",
    "partidos['VISITANTE_porcentaje_victoria_VISITANTE'] = (partidos['VISITANTE_Victorias_visitante']) / (partidos['VISITANTE_Victorias_visitante'] + partidos['VISITANTE_Derrotas_Visitante'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleccion de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = ['fecha', 'VISITANTE_porcentaje_victoria_Ultimos10', 'LOCAL_porcentaje_victoria_Ultimos10',\n",
    "               'LOCAL_porcentaje_victoria_LOCAL', 'VISITANTE_porcentaje_victoria_VISITANTE',\n",
    "               'LOCAL_Racha','VISITANTE_Racha','LOCAL_porcentajeVictorias',\n",
    "               'VISITANTE_porcentajeVictorias','target']\n",
    "\n",
    "data_1 = partidos[select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_clean = data_1.fillna(0) #NO ES LA FORMA CORRECTA, SE DEBE EVALUAR\n",
    "data_1_clean = data_1_clean[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar NAN en la base de datos derivado de los campos calculados (division de números entre ceros, sustituimos los NAN por ceros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustes de tipos de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_clean['fecha'] = pd.to_datetime(data_1_clean['fecha'].astype(str), format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_clean['target'] = data_1_clean['target'].astype(int)\n",
    "data_1_clean['LOCAL_Racha'] = data_1_clean['LOCAL_Racha'].astype(int)\n",
    "data_1_clean['VISITANTE_Racha'] = data_1_clean['VISITANTE_Racha'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.hist(figsize = (15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data_1_clean.loc[:,data_1_clean.columns != 'fecha'].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_clean.sort_values('fecha',ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Division de la base de datos en dataframes por temporada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORADA 2017-2018\n",
    "temporada_2017_2018 = data_1_clean[data_1_clean['fecha'] >= '2017-09-01']\n",
    "temporada_2017_2018 = temporada_2017_2018[temporada_2017_2018['fecha'] <= '2018-04-11'].sort_values('fecha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporada_2017_2018 = temporada_2017_2018.reset_index(drop=True)\n",
    "\n",
    "temporada_2017_2018.index = temporada_2017_2018.index + 1\n",
    "\n",
    "temporada_2017_2018.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORADA 2018-2019\n",
    "temporada_2018_2019 = data_1_clean[data_1_clean['fecha'] >= '2018-09-01']\n",
    "temporada_2018_2019 = temporada_2018_2019[temporada_2018_2019['fecha'] <= '2019-04-10'].sort_values('fecha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporada_2018_2019 = temporada_2018_2019.reset_index(drop=True)\n",
    "\n",
    "temporada_2018_2019.index = temporada_2018_2019.index + 1\n",
    "\n",
    "temporada_2018_2019.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANTE: Este paso debe suprimirse, se debe utilizar la metodología de alguno de los autores sobre la división de la BBDD.\n",
    "## Entrenamiento y Test\n",
    "Antes de comenzar con la creación del modelo es necesario separar la muestra en una para el entrenamiento y otra para la validación.\n",
    "\n",
    "Para empezar, realizaremos el enfoque mas sencillo, tomando como datos de entrenamiento la temporada previa a la temporada que vamos a estimar, en este contexto, tenemos:\n",
    "\n",
    "1. Train: temporada_2017_2018\n",
    "2. Test: temporada_2018_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAY QUE ELIMINAR LA SECUENCIA DE LOS DATOS POR FECHA\n",
    "\n",
    "variables = data_1_clean.loc[:, data_1_clean.columns != 'fecha']\n",
    "\n",
    "\n",
    "#variables_2017_2018 = temporada_2017_2018.loc[:,temporada_2017_2018.columns != 'fecha']\n",
    "\n",
    "#variables_2018_2019 = temporada_2018_2019.loc[:,temporada_2018_2019.columns != 'fecha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# variables_2017_2018, target_2017_2018 = temporada_2017_2018.iloc[:, :-1], temporada_2017_2018.iloc[:, -1:]\n",
    "#variables_2018_2019, target_2018_2019 = temporada_2018_2019.iloc[:, :-1], temporada_2018_2019.iloc[:, -1:]\n",
    "\n",
    "variables, target = variables.iloc[:, :-1], variables.iloc[:, -1:]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(variables, target, test_size = 0.5, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "x_train_std = sc.fit_transform(x_train, y_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función de Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def GS(a,b):\n",
    "    \"\"\"\"\"\n",
    "    Función que recibe dos parámetros;\n",
    "    :a: una variable binaria que representa 0 = bueno y 1 = malo (objetivo)\n",
    "    :b: predicción de la primera variable (continua, entera o binaria)\n",
    "    :return: coeficiente GINI de las dos variables anteriores. \"\"\"\n",
    "    \n",
    "    gini = 2*roc_auc_score(a,b)-1\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion de entranamiento de algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_method(x_train, y_train, x_test, y_test, method):  \n",
    "    \"\"\"\n",
    "    Funcion para entrenar un modelo con el método seleccionado\n",
    "    El entrenamiento y algoritmos son de la libreria de sklearn.\n",
    "    :param x_train: numpy array, required\n",
    "    :param y_train: numpy array, required\n",
    "    :param x_test: numpy array, required\n",
    "    :param y_test: numpy array, required    \n",
    "    :return: object\n",
    "        - Modelo entrenado según los datos\n",
    "    \"\"\"    \n",
    "    if method == 'LR':  # Linear Regresssion\n",
    "        return LR(x_train, y_train, x_test, y_test)\n",
    "    \n",
    "    elif method == 'LOGR': # Logistic Regresssion\n",
    "        return LOGR(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    elif method == 'DT': # Decision Tree Classifier\n",
    "        return DT(x_train, y_train, x_test, y_test)    \n",
    "    \n",
    "    elif method == 'LASSO': # Lasso Regresssion \n",
    "        return LASSO(x_train, y_train, x_test, y_test)\n",
    "    \n",
    "    elif method == 'RIDGE': # Ridge Regresssion\n",
    "        return RIDGE(x_train, y_train, x_test, y_test)\n",
    "    \n",
    "    elif method == 'RFR': # Random Forest Regressor\n",
    "        return RFR(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    elif method == 'RFC': # Random Forest Classifier\n",
    "        return RFC(x_train, y_train, x_test, y_test)    \n",
    "\n",
    "    elif method == 'GBR': # Gradient Boosting Regression\n",
    "        return GBR(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones resumen de algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def LR(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Linear Regresssion\n",
    "    \"\"\"\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    return prepare_dictionary_of_measures(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "def LOGR(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Logistic Regresssion\n",
    "    \"\"\"\n",
    "    model = LogisticRegression().fit(X_train, y_train)\n",
    "    return prepare_dictionary_of_measures(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def DT(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Decision Tree Classifier\n",
    "    \"\"\"\n",
    "    model = DecisionTreeClassifier(min_samples_split=20, random_state=99).fit(X_train, y_train)\n",
    "    return prepare_dictionary_of_measures(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "def LASSO(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Lasso Regresssion\n",
    "    \"\"\"\n",
    "    model = Lasso(alpha = 0.01).fit(X_train, y_train)\n",
    "    return prepare_dictionary_of_measures(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "def RIDGE(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Ridge Regresssion\n",
    "    \"\"\"\n",
    "    model = Ridge(alpha = 0.01).fit(X_train, y_train)\n",
    "    return prepare_dictionary_of_measures(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def RFR(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Random Forest Regressor\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor(n_estimators=1000, min_samples_split=2).fit(X_train, y_train)\n",
    "    return prepare_dictionary_of_measures(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def RFC(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Random Forest Classifier\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(n_estimators=1000, min_samples_split=2).fit(X_train, y_train)\n",
    "    return prepare_dictionary_of_measures(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "def GBR(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Gradient Boosting Regression\n",
    "    \"\"\"\n",
    "    model = GradientBoostingRegressor(n_estimators=1000,alpha=0.01).fit(X_train, y_train)\n",
    "    return prepare_dictionary_of_measures(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función de entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dictionary_of_measures(model, X_train, y_train, X_test, y_test):\n",
    "    # MEDIDAS DE PRUEBA\n",
    "    try: # Si es un método de clasificación, usamos la probabilidad.\n",
    "        y_pred_train = model.predict_proba(X_train)[:,1]\n",
    "    except:\n",
    "        y_pred_train = model.predict(X_test)\n",
    "        \n",
    "    a_train = model.score(X_train, y_train)\n",
    "    gini_train = GS(y_test,y_pred_train)    \n",
    "\n",
    "    # MEDIDAS DE TEST\n",
    "    try: # Si es un método de clasificación, usamos la probabilidad.\n",
    "        y_pred_test = model.predict_proba(X_test)[:,1]\n",
    "    except:\n",
    "        y_pred_test = model.predict(X_test) \n",
    "        \n",
    "    a_test = model.score(X_test, y_test)\n",
    "    gini_test = GS(y_test,y_pred_test)    \n",
    "\n",
    "    return {'model':model,'accuracy_train':a_train,'accuracy_test':a_test,\n",
    "            'gini_train':gini_train,'gini_test':gini_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_trained_model = train_method(x_train, y_train , x_test, y_test,\"LR\")\n",
    "print(dict_trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_trained_model = train_method(x_train, y_train ,x_test,y_test,\"LOGR\")\n",
    "print(dict_trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe de comparación de modelos (Gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_list = ['LR','LASSO', 'DT', 'LOGR','RIDGE','RFR','RFC','GBR']\n",
    "df_result_summary = pd.DataFrame(index=method_list,columns=['GINI-train','GINI-test', 'Caida %'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = []\n",
    "C2 = []\n",
    "C3 = []\n",
    "for method in method_list:\n",
    "    dict_trained_model[method] = train_method(x_train, y_train,x_test,y_test,method)\n",
    "    # Predicciones - REGRESSIONS\n",
    "    if method in ['LR','LASSO','RIDGE','RFR','GBR']: \n",
    "        y_pred_train = dict_trained_model[method]['model'].predict(x_train)\n",
    "        y_pred_test = dict_trained_model[method]['model'].predict(x_test)\n",
    "    else: # Predicciones - CLASSIFIERS \n",
    "        y_pred_train = dict_trained_model[method]['model'].predict_proba(x_train)[:,1]\n",
    "        y_pred_test = dict_trained_model[method]['model'].predict_proba(x_test)[:,1]\n",
    "    # Calculo de GINI\n",
    "    gini_score_train = GS(y_train,y_pred_train)\n",
    "    C1.append(gini_score_train)\n",
    "    gini_score_test = GS(y_test,y_pred_test)\n",
    "    C2.append(gini_score_test)\n",
    "    \n",
    "    diferencia = (1-(gini_score_test/gini_score_train)) * 100\n",
    "    C3.append(diferencia)\n",
    "    \n",
    "    \n",
    "# Adding the results to: df_result_summary\n",
    "df_result_summary ['GINI-train'] = C1\n",
    "df_result_summary ['GINI-test'] = C2\n",
    "df_result_summary ['Caida %'] = C3\n",
    "\n",
    "# Printing out the summary table\n",
    "df_result_summary.sort_values('Caida %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe de comparación de modelos (Accuracy)\n",
    "\n",
    "#### Accuracy (exactitud)\n",
    "La exactitud es una métrica para evaluar modelos de clasificación. \n",
    "\n",
    "Informalmente, la exactitud es la fracción de predicciones que el modelo realizó correctamente.\n",
    "\n",
    "Formalmente, la exactitud tiene la siguiente definición:\n",
    "\n",
    "##### Colocar formula con Latex\n",
    "\n",
    "Donde VP = Verdaderos positivos, VN = Verdaderos negativos, FP = Falsos positivos y FN = Falsos negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for method in method_list:\n",
    "    dict_trained_model[method] = train_method(x_train, y_train,x_test,y_test,method)\n",
    "#    print (dict_trained_model[method])\n",
    "    data.append([method, dict_trained_model[method]['accuracy_train'], dict_trained_model[method]['accuracy_test']])\n",
    "\n",
    "df_result_summary_2 = pd.DataFrame(data,columns=['method','accuracy_train','accuracy_test']) \n",
    "                \n",
    "df_result_summary_2.sort_values('accuracy_test', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparametrización RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "\n",
    "\n",
    "    estimator = RandomForestClassifier()\n",
    "    param_grid = { \n",
    "            \"n_estimators\"      : [20,25,30,500,1000],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [2,4,8,16],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=10)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFC(X_train, X_test, y_train, y_test, best_params):\n",
    "\n",
    "    estimator = RandomForestClassifier(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"GINI:\",GS(y_test,y_predict))\n",
    "    return y_test,y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print (\"Loop: \" , i)\n",
    "    print (\"--------------\")\n",
    "    # Es importante dividir el set de datos en partes iguales 50% train y 50% test\n",
    "    \n",
    "    best_score, best_params = Grid_Search_CV_RFR(x_train, y_train)\n",
    "    y_test , y_predict = RFC(x_train, x_test, y_train, y_test, best_params)\n",
    "    print (\"Best Score:\" ,best_score)\n",
    "    print (\"Best params:\",best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(train_set, train_labels, classifier_name, n_jobs=cpu_count()):\n",
    "    \"\"\"\n",
    "    The fitting process with sklearn algorithms.\n",
    "    :param train_set: numpy array, required\n",
    "    :param train_labels: list, required\n",
    "    :param classifier_name: string, required\n",
    "    :param n_jobs: integer, required\n",
    "    :return: object\n",
    "        - Fit classifier model according to the given training data\n",
    "    \"\"\"\n",
    "    classifier_list = {\"svm_linear\": SVC(probability=True, kernel='linear', C=1.0),\n",
    "                       \"svm_poly\": SVC(probability=True, kernel='poly', C=1.0),\n",
    "                       \"svm_rbf\": SVC(probability=True, kernel='rbf', C=1.0, gamma=0.01),\n",
    "                       \"linear_svc\": LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.1, C=1.0, multi_class='ovr', fit_intercept=True,\n",
    "                                               intercept_scaling=1, random_state=None, max_iter=3000),\n",
    "                       \"knn\": KNeighborsClassifier(n_neighbors=100, weights='distance', leaf_size=30, n_jobs=n_jobs),\n",
    "                       \"random_forests\": RandomForestClassifier(n_estimators=350, criterion='entropy', min_samples_split=2,\n",
    "                                                                min_samples_leaf=1, max_leaf_nodes=600, n_jobs=n_jobs),\n",
    "                       \"logistic_regression\": LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=2.4, fit_intercept=True, intercept_scaling=1,\n",
    "                                                                 random_state=None, solver='liblinear', max_iter=1000, multi_class='ovr',\n",
    "                                                                 warm_start=False, n_jobs=n_jobs),\n",
    "                       \"decision_trees\": DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2,\n",
    "                                                                min_samples_leaf=100, min_weight_fraction_leaf=0.0, max_features=None,\n",
    "                                                                random_state=None, max_leaf_nodes=None, presort=False),\n",
    "                       \"sgd\": SGDClassifier(alpha=.0001, n_iter=500, penalty=\"elasticnet\", n_jobs=n_jobs),\n",
    "                       \"neural_network\": Classifier(layers=[Layer(\"Sigmoid\", units=14), Layer(\"Sigmoid\", units=13), Layer(\"Sigmoid\", units=12),\n",
    "                                                            Layer(\"Sigmoid\", units=10), Layer(\"Softmax\")], learning_rate=0.01, n_iter=200,\n",
    "                                                    batch_size=10, regularize='L1', n_stable=50, dropout_rate=0, verbose=True),\n",
    "                       \"GBC\": GradientBoostingClassifier(max_depth=10, max_leaf_nodes=850, min_samples_leaf=15, learning_rate=0.1),\n",
    "                       \"XGB\": XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "                                            max_depth=10, min_child_weight=2, missing=None, n_estimators=100, nthread=n_jobs, reg_alpha=0,\n",
    "                                            objective='binary:logistic', reg_lambda=1, scale_pos_weight=1, seed=0, silent=True, subsample=1)}\n",
    "    return classifier_list[classifier_name].fit(train_set, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
